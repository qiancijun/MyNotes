# 一、Hadoop



## 1.1 Hadoop运行环境搭建（开发重点）

### 1.1.1 虚拟机环境准备

 1. 克隆虚拟机

 2. 修改克隆虚拟机的静态ip

 3. 修改主机名

 4. 关闭防火墙

 5. 创建用户

 6. 配置用户具有root权限

     1. `vim /etc/sudoers`

        ![](E:\Study\MyNotes\Hadoop\Linux-权限.png)

 7. 在`/opt`目录下创建文件夹

     1. 在`/opt`目录下创建module、software文件夹

     2. 修改module、software文件夹的所有者cd

     3. ```
        sudo chown 用户名:用户名 文件名
        ```



* 确保虚拟机与主机在同一网关下

    * windows ipconfig查看主机网关

        ![](E:\Study\MyNotes\Hadoop\Windows-主机网关.png)

    * 修改VMnet8网络配置

        ![](E:\Study\MyNotes\Hadoop\Windows-VMnet8.png)

    * 修改VMware虚拟网络地址

        ![](E:\Study\MyNotes\Hadoop\VMware配置.png)

* 设置静态ip，并且添加上本机ip地址`/etc/systemconfig/network-scripts/ifcfg-网卡名`

    ![](E:\Study\MyNotes\Hadoop\Linux-虚拟机环境配置1.png)

* 修改本机主机名称

    ```
    hostnamectl set-hostname xxx
    ```

* 修改/etc/hosts文件

    ![](E:\Study\MyNotes\Hadoop\Linux-虚拟机环境配置2.png)

### 1.1.2 安装JDK

1. 往`/opt/software`下传入jdk

2. 解压tar包

    * `tar -zxvf jdk文件名 -C /opt/module`

3. 配置JAVA_HOME

    * `sudo vim /etc/profile`

    * `shift + g`跳转到最后一行

    * ```
        export JAVA_HOME=jdk路径
        export PATH=$PATH:$JAVA_HOME/bin
        ```

    * 刷新profile文件`soruce /etc/profile`

    * `java -version`测试是否成功

### 1.1.3 安装Hadoop

1. 往`/opt/software`下传入源码文件

2. 解压tar包，同jdk方法

3. 配置HADOOP_HOME

    * ```
        export HADOOP_HOME=hadoop路径
        export PATH=$PATH:$HADOOP_HOMT/bin
        export PATH=$PATH:$HADOOP_HOMT/sbin
        ```

    * 刷新profile文件`soruce /etc/profile`

    * `hadoop`测试是否成功



## 1.2 Hadoop运行模式

Hadoop运行模式包括：本地模式、伪分布式模式以及完全分布式模式

[hadoop2.10.1官方文档](http://hadoop.apache.org/docs/r2.10.1/hadoop-project-dist/hadoop-common/SingleCluster.html)

### 1.2.1 本地运行模式

运行案例：

```
mkdir input
cp etc/hadoop/*.xml input
hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.1.jar grep input output 'dfs[a-z.]+'
```

运行成功后，目录下会多出一个output文件夹

![](E:\Study\MyNotes\Hadoop\Hadoop-本地模式案例.png)





### 1.2.2 官方WordCount案例

1. 在hadoop文件夹下面创建一个wcinput文件夹

    ```
    mkdir wcinput
    ```

    

2. 在wcinput文件下创建一个`wc.input`文件

3. 编辑`wc.input`文件，输入以下内容

    ``` 
    qiancijun
    Qianci
    Hello qiancijun
    Hello Qianci
    Bye qiancijun
    Bye Bye
    ```

4. 执行启动命令

    ```
    hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.1.jar wordcount wcininput/ wcoutput
    ```

5. 查看结果

    ![](E:\Study\MyNotes\Hadoop\Hadoop-官方WordCount案例.png)



### 1.2.3 伪分布式

​	

#### 启动HDFS并运行MR程序

1. 修改`etc/hadoop/core-site.xml`文件

    ``` 
    <!-- 指定HDFS中NameNode的地址  -->
    <configuration>
        <property>
            <name>fs.defaultFS</name>
            <value>hdfs://localhost:9000</value>
        </property>
        <!-- 指定Hadoop运行时产生文件的存储目录  -->
        <property>
            <name>hadoop.tmp.dir</name>
            <value>/opt/module/hadoop-2.10.1/data/tmp</value>
        </property>
    </configuration>
    ```

    > 其中localhost改为主机名

2. 修改`etc/hadoop/hdfs-site.xml`

    ``` 
    <!-- 指定HDFS副本的数量  -->
    <configuration>
        <property>
            <name>dfs.replication</name>
            <value>1</value>
        </property>
    </configuration>
    ```

3. 配置集群：

    1. 配置`hadoop-env.sh`

        * 修改`JAVA_HOME`路径伪Linux系统中路径

            >凡是env就修改JAVA_HOME

    2. 格式化NameNode（第一次启动时格式化，以后就不要格式化）

        ``` 
        bin/hdfs namenode -format
        ```

    3. 启动NameNode

        ```
        sbin/hadoop-daemon.sh start namenode
        ```

    4. 启动DataNode

        ```
        sbin/hadoop-daemon.sh start datanode
        ```

        > 使用jps命令查看是否启动了namenode与datanode
        >
        > 通过http://虚拟机ip:50070 来访问管理页面

        ![](E:\Study\MyNotes\Hadoop\Hadoop伪分布式管理页面.png)

    5. 创建文件树

        ```
        bin/hdfs dfs -mkdir -p /user/qiancijun/input
        ```

    6. 上传本地文件到HDFS

        ```
        bin/hdfs dfs -put wcininput/wc.input /user/qiancijun/input
        ```

    7. 启动MR程序进行测试，输出结果保存到HDFS、

        ```
        hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.1.jar wordcount /user/qiancijun/input /user/qiancijun/output
        ```

        ![](E:\Study\MyNotes\Hadoop\HDFS运行MR程序.png)

        `/user/qiancijun/output`文件夹不可以提前创建

        使用`bin/hdfs dfs -cat`来查看结果

        ![](E:\Study\MyNotes\Hadoop\HDFS-Linux下查看运行结果.png)



#### Log日志查看与Namenode格式化

* NameNode格式化注意事项

    * 先检查namenode与datanode进程是否关闭

    * 将data文件夹删除

    * 格式化Namenode

        ![](E:\Study\MyNotes\Hadoop\Namenode与Datanode集群ID.png)

        datanode集群ID：609285c6-bfd6-463d-95f6-2cbbe8a18c6a

        namenode集群ID：609285c6-bfd6-463d-95f6-2cbbe8a18c6a

* Logs文件目录

    ![](E:\Study\MyNotes\Hadoop\Logs文件目录.png)



#### 启动YARN并运行MR程序

1. 配置`/etc/hadoop/yarn-env.sh`中的JAVA_HOME

    ![](E:\Study\MyNotes\Hadoop\yarn-env.sh配置.png)

2. 配置`etc/hadoop/yarn-site.xml`

    ```
    <configuration>
    
    <!-- Site specific YARN configuration properties -->
    	<!-- 指定Reduce获取的方式  -->
        <property>
            <name>yarn.nodemanager.aux-services</name>
            <value>mapreduce_shuffle</value>
        </property>
        <!-- 指定YARN的ResourceManager的地址  -->
        <property>
            <name>yarn.resourcemanager.hostname</name>
            <value>hadoop01</value>
        </property>
    </configuration>
    ```

3. 配置`etc/hadoop/mapred-env.sh`的JAVA_HOME

    ![](E:\Study\MyNotes\Hadoop\mapred-env.sh配置.png)

4. 把`etc/hadoop/mapred-site.xml.template`文件重命名为`mapred-site.xml`

    ```
    mv mapred-site.xml.template mapred-site.xml
    ```

5. 配置`etc/hadoop/mapred-site.xml`

    ```
    <configuration>
    
    	<!-- 指定MR运行在YARN上  -->
        <property>
            <name>mapreduce.framework.name</name>
            <value>yarn</value>
        </property>
    
    </configuration>
    ```

6. 启动集群

    1. 启动`resourcemanager`

        ```
        sbin/yarn-daemon.sh start resourcemanager
        ```

    2. 启动`nodemanager`

        ```
        sbin/yarn-daemon.sh start nodemanager
        ```

    3. `jps`查看是否启动

        ![](E:\Study\MyNotes\Hadoop\YARN启动集群.png)

        `http://虚拟机IP:8088/`进入管理页面查看是否启动

    4. 启动MR程序进行测试

        ```
        hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.1.jar wordcount /user/qiancijun/input /user/qiancijun/output
        ```

        ![](E:\Study\MyNotes\Hadoop\YARN测试MR程序.png)

7. 配置历史服务器

    1. 配置`mapred-site.xml`

        ```
        <configuration>
        
            <property>
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
            </property>
        
        <!-- 历史服务器端地址 -->
            <property>
                <name>mapreduce.jobhistory.address</name>
                <value>hadoop01:10020</value>
            </property>
        <!-- 历史服务器web端地址 -->
            <property>
                <name>mapreduce.jobhistory.webapp.address</name>
                <value>hadoop01:19888</value>
            </property>
        
        </configuration>
        ```

    2. 启动历史服务器

        ```
        sbin/mr-jobhistory-daemon.sh start historyserver
        ```

    3. 使用`jps`查看历史服务器是否启动

    4. 查看JobHistory`http://虚拟机IP:19888/jobhistory`

        ![](E:\Study\MyNotes\Hadoop\历史服务器.png)

#### 配置日志的聚集

应用运行完成以后，将程序运行日志信息上传到HDFS系统上。可以方便的查看到程序运行详情，方便开发调试。

1. 关闭NodeManager 、ResourceManager和HistoryManager

    ```
    sbin/yarn-daemon.sh stop resourcemanager
    sbin/yarn-daemon.sh stop nodemanager
    sbin/mr-jobhistory-daemon.sh stop historyserver
    ```

    使用`jps`查看是否成功关闭

2. 配置`yarn-site.xml`

    ```
    <!-- 日志聚集功能使能 -->
    	<property>
    		<name>yarn.log-aggregation-enable</name>
    		<value>true</value>
    	</property>
    <!-- 日志保留时间设置7天 -->
    	<property>
    		<name>yarn.log-aggregation.retain-seconds</name>
    		<value>604800</value>
    	</property>
    ```

3. 启动NodeManager 、ResourceManager和HistoryManager

4. 删除HDFS上已经存在的输出文件

5. 执行WordCount程序

    ```
    hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.1.jar wordcount /user/qiancijun/input /user/qiancijun/output
    ```

6. 查看日志

    ![](E:\Study\MyNotes\Hadoop\历史服务器-日志聚集.png)



### 1.2.4 完全分布式(开发重点)



#### 虚拟机准备

同1.1.1部分内容



#### 编写集群分发脚本xsync

1. scp（secure copy）安全拷贝

    * scp可以实现服务器与服务器之间的数据拷贝。（from server1 to server2）

    * 基本语法`scp -r $pdir/$fname $user@hostName:$pdir/$fname `

    * 案例：将hadoop01下module目录下的软件拷贝到hadoop02下

        ```
        scp -r /opt/module/ root@hadoop02:/opt/module
        ```

2. rsync 远程同步工具

    * rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。

    * rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。

    * 基本语法

        ``` 
        rsync -rvl $pdir/$fname $user@hadoop$host:$pdir/$fname
        ```

        > -r 递归
        >
        > -v 显示复制过程
        >
        > -l 拷贝符号连接

3. xsync集群分发脚本

    * 循环复制文件到所有节点的相同目录下

    * 期望脚本：`xsync 要同步的文件名称`

        > 在/home/用户名/bin这个目录下存放的脚本，用户可以在系统任何地方直接执行。

    * 脚本实现：

        在`/home/用户名`目录下创建bin目录，并在`bin`目录下`xsync`创建文件

        ```shell
        #!/bin/bash
        #1 获取输入参数个数，如果没有参数，直接退出
        pcount=$#
        if((pcount==0)); then
        echo no args;
        exit;
        fi
        
        #2 获取文件名称
        p1=$1
        fname=`basename $p1`
        echo fname=$fname
        
        #3 获取上级目录到绝对路径
        pdir=`cd -P $(dirname $p1); pwd`
        echo pdir=$pdir
        
        #4 获取当前用户名称
        user=`whoami`
        
        #5 循环
        for((host=103; host<105; host++)); do
                echo ------------------- hadoop$host --------------
                rsync -rvl $pdir/$fname $user@hadoop$host:$pdir
        done
        ```

        修改脚本 xsync 具有执行权限

        ```
        chmod 777 xsync
        ```

        > 注意：如果将xsync放到/home/用户名/bin目录下仍然不能实现全局使用，可以将xsync移动到/usr/local/bin目录下。



#### 集群配置

1. 集群部署规划

    |      | hadoop02               | hadoop03                         | hadoop04                        |
    | ---- | ---------------------- | -------------------------------- | ------------------------------- |
    | HDFS | NameNode<br />DataNode | DataNode                         | SecondaryNameNode<br />DataNode |
    | YARN | NodeManager            | ResourceManager<br />NodeManager | NodeManager                     |

2. 配置集群

    1. 配置`core-site.xml`

        ```
        <configuration>
            <property>
                <name>fs.defaultFS</name>
                <value>hdfs://hadoop02:9000</value>
            </property>
            <property>
                <name>hadoop.tmp.dir</name>
                <value>/opt/module/hadoop-2.10.1/data/tmp</value>
            </property>
        </configuration>
        ```

    2. 配置HDFS

        配置`hadoop-env.sh`，同伪分布式的操作

        配置`hdfs-site.xml`

        ```
        <configuration>
        
            <property>
                <name>dfs.replication</name>
                <value>3</value>
            </property>
            <!-- 指定Hadoop辅助名称节点主机配置 -->
            <property>
                <name>dfs.namenode.secondary.http-address</name>
                <value>hadoop04:50090</value>
            </property>
        
        </configuration>
        
        ```

    3. 配置YARN

        配置`yarn-env.sh`

        配置`yarn-site.xml`

        ```
        <configuration>
        
            <!-- Reducer获取数据的方式 -->
            <property>
                <name>yarn.nodemanager.aux-services</name>
                <value>mapreduce_shuffle</value>
            </property>
            <!-- 指定YARN的ResourceManager的地址 -->
            <property>
                <name>yarn.resourcemanager.hostname</name>
                <value>hadoop03</value>
            </property>
            <property>
                <name>yarn.log-aggregation-enable</name>
                <value>true</value>
            </property>
            <property>
                <name>yarn.log-aggregation.retain-seconds</name>
                <value>604800</value>
            </property>
        
        </configuration>
        ```

    4. 配置MapReduce

        配置`mapred-env.sh`

        配置`mapred-site.xml`

        ```
        <configuration>
        
            <property>
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
            </property>
        
        </configuration>
        ```

    5. 在集群上分发配置好的Hadoop配置文件

        ```
        xsync hadoop/
        ```



#### 集群的单节点启动

* 启动方式同伪分布式，注意表格，只需要启动部分进程

#### 集群ssh免密登录

 1. 无密钥配置

    原理图：

    ![](E:\Study\MyNotes\Hadoop\免密登录原理.png)

	2. 生成公钥和私钥

    ```
    ssh-keygen -t rsa
    ```

    敲三个回车，就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）

	3. 将公钥拷贝到要免密登录的目标机器上

    ```
    ssh-copy-id hadoop02
    ssh-copy-id hadoop03
    ssh-copy-id hadoop04
    ```

	4. .ssh文件夹下（~/.ssh）的文件功能解释

    | known_hosts     | 记录ssh访问过计算机的公钥(public key) |
    | --------------- | ------------------------------------- |
    | id_rsa          | 生成的私钥                            |
    | id_rsa.pub      | 生成的公钥                            |
    | authorized_keys | 存放授权过得无密登录服务器公钥        |

    

> 注意：
>
> 还需要在hadoop02上采用root账号，配置一下无密登录到hadoop02、hadoop03、hadoop04；
>
> 还需要在hadoop03上采用自己用户账号配置一下无密登录到hadoop02、hadoop03、hadoop04服务器上。

​	

#### 群起集群

1.  配置slaves：`/opt/module/hadoop-2.10.1/etc/hadoop/slaves`

    ```
    hadoop02
    hadoop03
    hadoop04
    ```

    > 注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。

2. 同步所有节点配置文件

    ```
    xsync slaves
    ```

3. 启动集群

    * 如果集群是第一次启动，需要格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据）

        ``` 
        bin/hdfs namenode -format
        ```

    * 启动HDFS

        ```
        sbin/start-dfs.sh
        ```

        ![](E:\Study\MyNotes\Hadoop\集群配置-hdfs启动.png)

    * 启动YARN

        ```
        sbin/start-yarn.sh
        ```

        > 注意：NameNode和ResourceManger如果不是同一台机器，不能在NameNode上启动 YARN，应该在ResouceManager所在的机器上启动YARN。

        ![](E:\Study\MyNotes\Hadoop\集群配置-yarn启动.png)



#### 集群基本测试

 1. 上传文件到集群

    ```
    hdfs dfs -put wcininput/wc.input /
    ```

 2. 打开`IP:50070`网页控制台查看文件是否上传

    ![](E:\Study\MyNotes\Hadoop\集群配置-测试集群.png)

    ![](E:\Study\MyNotes\Hadoop\集群配置-测试集群2.png)



####  集群启动/停止方式总结

1. 各个服务组件逐一启动/停止

    * 分别启动/停止HDFS组件

        ```
        hadoop-daemon.sh  start / stop  namenode / datanode / secondarynamenode
        ```

    * 启动/停止YARN

        ```
        yarn-daemon.sh  start / stop  resourcemanager / nodemanager
        ```

2. 各个模块分开启动/停止（配置ssh是前提）

    * 整体启动/停止HDFS

        ```
        start-dfs.sh   /  stop-dfs.sh
        ```

    * 整体启动/停止YARN

        ```
        start-yarn.sh  /  stop-yarn.sh
        ```

        