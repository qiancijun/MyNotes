# 一、Hadoop



## 1.1 Hadoop运行环境搭建（开发重点）

### 1.1.1 虚拟机环境准备

 1. 克隆虚拟机

 2. 修改克隆虚拟机的静态ip

 3. 修改主机名

 4. 关闭防火墙

 5. 创建用户

 6. 配置用户具有root权限

     1. `vim /etc/sudoers`

        ![](Hadoop\Linux-权限.png)

 7. 在`/opt`目录下创建文件夹

     1. 在`/opt`目录下创建module、software文件夹

     2. 修改module、software文件夹的所有者cd

     3. ```
        sudo chown 用户名:用户名 文件名
        ```



* 确保虚拟机与主机在同一网关下

    * windows ipconfig查看主机网关

        ![](Hadoop\Windows-主机网关.png)

    * 修改VMnet8网络配置

        ![](Hadoop\Windows-VMnet8.png)

    * 修改VMware虚拟网络地址

        ![](Hadoop\VMware配置.png)

* 设置静态ip，并且添加上本机ip地址`/etc/systemconfig/network-scripts/ifcfg-网卡名`

    ![](Hadoop\Linux-虚拟机环境配置1.png)

* 修改本机主机名称

    ```
    hostnamectl set-hostname xxx
    ```

* 修改/etc/hosts文件

    ![](Hadoop\Linux-虚拟机环境配置2.png)

### 1.1.2 安装JDK

1. 往`/opt/software`下传入jdk

2. 解压tar包

    * `tar -zxvf jdk文件名 -C /opt/module`

3. 配置JAVA_HOME

    * `sudo vim /etc/profile`

    * `shift + g`跳转到最后一行

    * ```
        export JAVA_HOME=jdk路径
        export PATH=$PATH:$JAVA_HOME/bin
        ```

    * 刷新profile文件`soruce /etc/profile`

    * `java -version`测试是否成功

### 1.1.3 安装Hadoop

1. 往`/opt/software`下传入源码文件

2. 解压tar包，同jdk方法

3. 配置HADOOP_HOME

    * ```
        export HADOOP_HOME=hadoop路径
        export PATH=$PATH:$HADOOP_HOMT/bin
        export PATH=$PATH:$HADOOP_HOMT/sbin
        ```

    * 刷新profile文件`soruce /etc/profile`

    * `hadoop`测试是否成功



## 1.2 Hadoop运行模式

Hadoop运行模式包括：本地模式、伪分布式模式以及完全分布式模式

[hadoop2.10.1官方文档](http://hadoop.apache.org/docs/r2.10.1/hadoop-project-dist/hadoop-common/SingleCluster.html)

### 1.2.1 本地运行模式

运行案例：

```
mkdir input
cp etc/hadoop/*.xml input
hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.1.jar grep input output 'dfs[a-z.]+'
```

运行成功后，目录下会多出一个output文件夹

![](E:\Study\MyNotes\Hadoop\Hadoop-本地模式案例.png)





### 1.2.2 官方WordCount案例

1. 在hadoop文件夹下面创建一个wcinput文件夹

    ```
    mkdir wcinput
    ```

    

2. 在wcinput文件下创建一个`wc.input`文件

3. 编辑`wc.input`文件，输入以下内容

    ``` 
    qiancijun
    Qianci
    Hello qiancijun
    Hello Qianci
    Bye qiancijun
    Bye Bye
    ```

4. 执行启动命令

    ```
    hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.1.jar wordcount wcininput/ wcoutput
    ```

5. 查看结果

    ![](Hadoop\Hadoop-官方WordCount案例.png)



### 1.2.3 伪分布式

​	

#### 启动HDFS并运行MR程序

1. 修改`etc/hadoop/core-site.xml`文件

    ``` 
    <!-- 指定HDFS中NameNode的地址  -->
    <configuration>
        <property>
            <name>fs.defaultFS</name>
            <value>hdfs://localhost:9000</value>
        </property>
        <!-- 指定Hadoop运行时产生文件的存储目录  -->
        <property>
            <name>hadoop.tmp.dir</name>
            <value>/opt/module/hadoop-2.10.1/data/tmp</value>
        </property>
    </configuration>
    ```

    > 其中localhost改为主机名

2. 修改`etc/hadoop/hdfs-site.xml`

    ``` 
    <!-- 指定HDFS副本的数量  -->
    <configuration>
        <property>
            <name>dfs.replication</name>
            <value>1</value>
        </property>
    </configuration>
    ```

3. 配置集群：

    1. 配置`hadoop-env.sh`

        * 修改`JAVA_HOME`路径伪Linux系统中路径

            >凡是env就修改JAVA_HOME

    2. 格式化NameNode（第一次启动时格式化，以后就不要格式化）

        ``` 
        bin/hdfs namenode -format
        ```

    3. 启动NameNode

        ```
        sbin/hadoop-daemon.sh start namenode
        ```

    4. 启动DataNode

        ```
        sbin/hadoop-daemon.sh start datanode
        ```

        > 使用jps命令查看是否启动了namenode与datanode
        >
        > 通过http://虚拟机ip:50070 来访问管理页面

        ![](Hadoop\Hadoop伪分布式管理页面.png)

    5. 创建文件树

        ```
        bin/hdfs dfs -mkdir -p /user/qiancijun/input
        ```

    6. 上传本地文件到HDFS

        ```
        bin/hdfs dfs -put wcininput/wc.input /user/qiancijun/input
        ```

    7. 启动MR程序进行测试，输出结果保存到HDFS、

        ```
        hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.1.jar wordcount /user/qiancijun/input /user/qiancijun/output
        ```

        ![](Hadoop\HDFS运行MR程序.png)

        `/user/qiancijun/output`文件夹不可以提前创建

        使用`bin/hdfs dfs -cat`来查看结果

        ![](Hadoop\HDFS-Linux下查看运行结果.png)



#### Log日志查看与Namenode格式化

* NameNode格式化注意事项

    * 先检查namenode与datanode进程是否关闭

    * 将data文件夹删除

    * 格式化Namenode

        ![](Hadoop\Namenode与Datanode集群ID.png)

        datanode集群ID：609285c6-bfd6-463d-95f6-2cbbe8a18c6a

        namenode集群ID：609285c6-bfd6-463d-95f6-2cbbe8a18c6a

* Logs文件目录

    ![](Hadoop\Logs文件目录.png)



#### 启动YARN并运行MR程序

1. 配置`/etc/hadoop/yarn-env.sh`中的JAVA_HOME

    ![](Hadoop\yarn-env.sh配置.png)

2. 配置`etc/hadoop/yarn-site.xml`

    ```
    <configuration>
    
    <!-- Site specific YARN configuration properties -->
    	<!-- 指定Reduce获取的方式  -->
        <property>
            <name>yarn.nodemanager.aux-services</name>
            <value>mapreduce_shuffle</value>
        </property>
        <!-- 指定YARN的ResourceManager的地址  -->
        <property>
            <name>yarn.resourcemanager.hostname</name>
            <value>hadoop01</value>
        </property>
    </configuration>
    ```

3. 配置`etc/hadoop/mapred-env.sh`的JAVA_HOME

    ![](Hadoop\mapred-env.sh配置.png)

4. 把`etc/hadoop/mapred-site.xml.template`文件重命名为`mapred-site.xml`

    ```
    mv mapred-site.xml.template mapred-site.xml
    ```

5. 配置`etc/hadoop/mapred-site.xml`

    ```
    <configuration>
    
    	<!-- 指定MR运行在YARN上  -->
        <property>
            <name>mapreduce.framework.name</name>
            <value>yarn</value>
        </property>
    
    </configuration>
    ```

6. 启动集群

    1. 启动`resourcemanager`

        ```
        sbin/yarn-daemon.sh start resourcemanager
        ```

    2. 启动`nodemanager`

        ```
        sbin/yarn-daemon.sh start nodemanager
        ```

    3. `jps`查看是否启动

        ![](Hadoop\YARN启动集群.png)

        `http://虚拟机IP:8088/`进入管理页面查看是否启动

    4. 启动MR程序进行测试

        ```
        hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.1.jar wordcount /user/qiancijun/input /user/qiancijun/output
        ```

        ![](Hadoop\YARN测试MR程序.png)

7. 配置历史服务器

    1. 配置`mapred-site.xml`

        ```
        <configuration>
        
            <property>
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
            </property>
        
        <!-- 历史服务器端地址 -->
            <property>
                <name>mapreduce.jobhistory.address</name>
                <value>hadoop01:10020</value>
            </property>
        <!-- 历史服务器web端地址 -->
            <property>
                <name>mapreduce.jobhistory.webapp.address</name>
                <value>hadoop01:19888</value>
            </property>
        
        </configuration>
        ```

    2. 启动历史服务器

        ```
        sbin/mr-jobhistory-daemon.sh start historyserver
        ```

    3. 使用`jps`查看历史服务器是否启动

    4. 查看JobHistory`http://虚拟机IP:19888/jobhistory`

        ![](Hadoop\历史服务器.png)

#### 配置日志的聚集

应用运行完成以后，将程序运行日志信息上传到HDFS系统上。可以方便的查看到程序运行详情，方便开发调试。

1. 关闭NodeManager 、ResourceManager和HistoryManager

    ```
    sbin/yarn-daemon.sh stop resourcemanager
    sbin/yarn-daemon.sh stop nodemanager
    sbin/mr-jobhistory-daemon.sh stop historyserver
    ```

    使用`jps`查看是否成功关闭

2. 配置`yarn-site.xml`

    ```
    <!-- 日志聚集功能使能 -->
    	<property>
    		<name>yarn.log-aggregation-enable</name>
    		<value>true</value>
    	</property>
    <!-- 日志保留时间设置7天 -->
    	<property>
    		<name>yarn.log-aggregation.retain-seconds</name>
    		<value>604800</value>
    	</property>
    ```

3. 启动NodeManager 、ResourceManager和HistoryManager

4. 删除HDFS上已经存在的输出文件

5. 执行WordCount程序

    ```
    hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.1.jar wordcount /user/qiancijun/input /user/qiancijun/output
    ```

6. 查看日志

    ![](Hadoop\历史服务器-日志聚集.png)



### 1.2.4 完全分布式(开发重点)



#### 虚拟机准备

同1.1.1部分内容



#### 编写集群分发脚本xsync

1. scp（secure copy）安全拷贝

    * scp可以实现服务器与服务器之间的数据拷贝。（from server1 to server2）

    * 基本语法`scp -r $pdir/$fname $user@hostName:$pdir/$fname `

    * 案例：将hadoop01下module目录下的软件拷贝到hadoop02下

        ```
        scp -r /opt/module/ root@hadoop02:/opt/module
        ```

2. rsync 远程同步工具

    * rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。

    * rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。

    * 基本语法

        ``` 
        rsync -rvl $pdir/$fname $user@hadoop$host:$pdir/$fname
        ```

        > -r 递归
        >
        > -v 显示复制过程
        >
        > -l 拷贝符号连接

3. xsync集群分发脚本

    * 循环复制文件到所有节点的相同目录下

    * 期望脚本：`xsync 要同步的文件名称`

        > 在/home/用户名/bin这个目录下存放的脚本，用户可以在系统任何地方直接执行。

    * 脚本实现：

        在`/home/用户名`目录下创建bin目录，并在`bin`目录下`xsync`创建文件

        ```shell
        #!/bin/bash
        #1 获取输入参数个数，如果没有参数，直接退出
        pcount=$#
        if((pcount==0)); then
        echo no args;
        exit;
        fi
        
        #2 获取文件名称
        p1=$1
        fname=`basename $p1`
        echo fname=$fname
        
        #3 获取上级目录到绝对路径
        pdir=`cd -P $(dirname $p1); pwd`
        echo pdir=$pdir
        
        #4 获取当前用户名称
        user=`whoami`
        
        #5 循环
        for((host=103; host<105; host++)); do
                echo ------------------- hadoop$host --------------
                rsync -rvl $pdir/$fname $user@hadoop$host:$pdir
        done
        ```

        修改脚本 xsync 具有执行权限

        ```
        chmod 777 xsync
        ```

        > 注意：如果将xsync放到/home/用户名/bin目录下仍然不能实现全局使用，可以将xsync移动到/usr/local/bin目录下。



#### 集群配置

1. 集群部署规划

    |      | hadoop02               | hadoop03                         | hadoop04                        |
    | ---- | ---------------------- | -------------------------------- | ------------------------------- |
    | HDFS | NameNode<br />DataNode | DataNode                         | SecondaryNameNode<br />DataNode |
    | YARN | NodeManager            | ResourceManager<br />NodeManager | NodeManager                     |

2. 配置集群

    1. 配置`core-site.xml`

        ```
        <configuration>
            <property>
                <name>fs.defaultFS</name>
                <value>hdfs://hadoop02:9000</value>
            </property>
            <property>
                <name>hadoop.tmp.dir</name>
                <value>/opt/module/hadoop-2.10.1/data/tmp</value>
            </property>
        </configuration>
        ```

    2. 配置HDFS

        配置`hadoop-env.sh`，同伪分布式的操作

        配置`hdfs-site.xml`

        ```
        <configuration>
        
            <property>
                <name>dfs.replication</name>
                <value>3</value>
            </property>
            <!-- 指定Hadoop辅助名称节点主机配置 -->
            <property>
                <name>dfs.namenode.secondary.http-address</name>
                <value>hadoop04:50090</value>
            </property>
        
        </configuration>
        
        ```

    3. 配置YARN

        配置`yarn-env.sh`

        配置`yarn-site.xml`

        ```
        <configuration>
        
            <!-- Reducer获取数据的方式 -->
            <property>
                <name>yarn.nodemanager.aux-services</name>
                <value>mapreduce_shuffle</value>
            </property>
            <!-- 指定YARN的ResourceManager的地址 -->
            <property>
                <name>yarn.resourcemanager.hostname</name>
                <value>hadoop03</value>
            </property>
            <property>
                <name>yarn.log-aggregation-enable</name>
                <value>true</value>
            </property>
            <property>
                <name>yarn.log-aggregation.retain-seconds</name>
                <value>604800</value>
            </property>
        
        </configuration>
        ```

    4. 配置MapReduce

        配置`mapred-env.sh`

        配置`mapred-site.xml`

        ```
        <configuration>
        
            <property>
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
            </property>
        
        </configuration>
        ```

    5. 在集群上分发配置好的Hadoop配置文件

        ```
        xsync hadoop/
        ```



#### 集群的单节点启动

* 启动方式同伪分布式，注意表格，只需要启动部分进程

#### 集群ssh免密登录

 1. 无密钥配置

    原理图：

    ![](Hadoop\免密登录原理.png)

	2. 生成公钥和私钥

    ```
    ssh-keygen -t rsa
    ```

    敲三个回车，就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）

	3. 将公钥拷贝到要免密登录的目标机器上

    ```
    ssh-copy-id hadoop02
    ssh-copy-id hadoop03
    ssh-copy-id hadoop04
    ```

	4. .ssh文件夹下（~/.ssh）的文件功能解释

    | known_hosts     | 记录ssh访问过计算机的公钥(public key) |
    | --------------- | ------------------------------------- |
    | id_rsa          | 生成的私钥                            |
    | id_rsa.pub      | 生成的公钥                            |
    | authorized_keys | 存放授权过得无密登录服务器公钥        |

    

> 注意：
>
> 还需要在hadoop02上采用root账号，配置一下无密登录到hadoop02、hadoop03、hadoop04；
>
> 还需要在hadoop03上采用自己用户账号配置一下无密登录到hadoop02、hadoop03、hadoop04服务器上。

​	

#### 群起集群

1.  配置slaves：`/opt/module/hadoop-2.10.1/etc/hadoop/slaves`

    ```
    hadoop02
    hadoop03
    hadoop04
    ```

    > 注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。

2. 同步所有节点配置文件

    ```
    xsync slaves
    ```

3. 启动集群

    * 如果集群是第一次启动，需要格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据）

        ``` 
        bin/hdfs namenode -format
        ```

    * 启动HDFS

        ```
        sbin/start-dfs.sh
        ```

        ![](Hadoop\集群配置-hdfs启动.png)

    * 启动YARN

        ```
        sbin/start-yarn.sh
        ```

        > 注意：NameNode和ResourceManger如果不是同一台机器，不能在NameNode上启动 YARN，应该在ResouceManager所在的机器上启动YARN。

        ![](Hadoop\集群配置-yarn启动.png)



#### 集群基本测试

 1. 上传文件到集群

    ```
    hdfs dfs -put wcininput/wc.input /
    ```

 2. 打开`IP:50070`网页控制台查看文件是否上传

    ![](Hadoop\集群配置-测试集群.png)

    ![](Hadoop\集群配置-测试集群2.png)



####  集群启动/停止方式总结

1. 各个服务组件逐一启动/停止

    * 分别启动/停止HDFS组件

        ```
        hadoop-daemon.sh  start / stop  namenode / datanode / secondarynamenode
        ```

    * 启动/停止YARN

        ```
        yarn-daemon.sh  start / stop  resourcemanager / nodemanager
        ```

2. 各个模块分开启动/停止（配置ssh是前提）

    * 整体启动/停止HDFS

        ```
        start-dfs.sh   /  stop-dfs.sh
        ```

    * 整体启动/停止YARN

        ```
        start-yarn.sh  /  stop-yarn.sh
        ```




#### 集群时间同步

时间同步的方式：找一个机器，作为时间服务器，所有的机器与这台集群时间进行定时的同步，比如，每隔十分钟，同步一次时间。

**配置时间同步具体实操：**

1. 时间服务器配置（必须root用户）

    1. 检查ntp是否安装

        ``` 
        rpm -qa|grep ntp
        ```

        > ntp-4.2.6p5-10.el6.centos.x86_64
        >
        > fontpackages-filesystem-1.41-1.1.el6.noarch
        >
        > ntpdate-4.2.6p5-10.el6.centos.x86_64

    2. 修改ntp配置文件

        ```
        vim /etc/ntp.conf
        ```

        修改内容如下:

        修改1（授权192.168.1.0-192.168.1.255网段上的所有机器可以从这台机器上查询和同步时间，检查自己虚拟机的网络配置）

        ``` 
        #restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap
        为
        restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap
        ```

        修改2（集群在局域网中，不使用其他互联网上的时间）

        ```
        server 0.centos.pool.ntp.org iburst
        server 1.centos.pool.ntp.org iburst
        server 2.centos.pool.ntp.org iburst
        server 3.centos.pool.ntp.org iburst
        为
        #server 0.centos.pool.ntp.org iburst
        #server 1.centos.pool.ntp.org iburst
        #server 2.centos.pool.ntp.org iburst
        #server 3.centos.pool.ntp.org iburst
        ```

        添加3（当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步）

        ``` 
        server 127.127.1.0
        fudge 127.127.1.0 stratum 10
        ```

    3. 修改/etc/sysconfig/ntpd 文件

        ``` 
        vim /etc/sysconfig/ntpd
        ```

        增加内容如下（让硬件时间与系统时间一起同步）

        ```
        SYNC_HWCLOCK=yes
        ```

    4. 重新启动ntpd服务

        ```
        service ntpd status
        service ntpd start
        ```

    5. 设置ntpd服务开机启动

        ``` 
        chkconfig ntpd on
        ```

2. 其他机器配置（必须root用户）

    1. 在其他机器配置10分钟与时间服务器同步一次

        ``` 
        crontab -e
        ```

        编写定时任务如下：

        ```
        */10 * * * * /usr/sbin/ntpdate hadoop102
        ```

    2. 修改任意机器时间

        ``` 
        date -s "2017-9-11 11:11:11"
        ```

    3. 十分钟后查看机器是否与时间服务器同步

        ```
        date
        ```

    > 说明：测试的时候可以将10分钟调整为1分钟，节省时间。

# 二、HDFS

## 2.1 HDFS产出背景及定义

### 2.1.1 HDFS产生背景

* 随着数据量越来越大，在一个操作系统存不下所有的数据，那么就分配到更多的操作系统管理的磁盘中，但是不方便管理和维护，迫切需要一种系统来管理多台机器上的文件，这就是分布式文件管理系统。HDFS只是分布式文件管理系统中的一种。



### 2.1.2 HDFS定义

* HDFS（Hadoop Distributed File System），它是一个文件系统，用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。

* HDFS的使用场景：适合一次写入，多次读出的场景，且不支持文件的修改。适合用来做数据分析，并不适合用来做网盘应用。



## 2.2 HDFS优缺点



### 2.2.1 优点

1. 高容错性	
    * 数据自动保存多个副本。它通过增加副本的形式，提高容错性。
    * 某一个副本丢失以后，它可以自动恢复。
2. 适合处理大数据
    * 数据规模：能够处理数据规模达到GB、TB、甚至PB级别的数据；
    * 文件规模：能够处理百万规模以上的文件数量，数量相当之大。
3. 可构建在廉价机器上，通过多副本机制，提高可靠性。

### 2.2.2 缺点

	1. 不适合低延时数据访问，比如毫秒级的存储数据，是做不到的。
 	2. 无法高效的对大量小文件进行存储。
     * 存储大量小文件的话，它会占用NameNode大量的内存来存储文件目录和块信息。这样是不可取的，因为NameNode的内存总是有限的；
     * 小文件存储的寻址时间会超过读取时间，它违反了HDFS的设计目标。
	3. 不支持并发写入、文件随机修改。

    * 一个文件只能有一个写，不允许多个线程同时写；
    * 仅支持数据append（追加），不支持文件的随机修改。



## 2.3 HDFS组成架构

1. NameNode（nn）：就是Master，它是一个主管、管理者。
    * 管理HDFS的名称空间；
    * 配置副本策略；
    * 管理数据块（Block）映射信息；
    * 处理客户端读写请求。
2. DataNode：就是Slave。NameNode下达命令，DataNode执行实际的操作。
    * 存储实际的数据块；
    * 执行数据块的读/写操作。
3. Client：就是客户端。
    * 文件切分。文件上传HDFS的时候，Client将文件切分成一个一个的Block，然后进行上传；
    * 与NameNode交互，获取文件的位置信息；
    * 与DataNode交互，读取或者写入数据；
    * Client提供一些命令来管理HDFS，比如NameNode格式化；
    * Client可以通过一些命令来访问HDFS，比如对HDFS增删查改操作；
4. Secondary NameNode：并非NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。
    * 辅助NameNode，分担其工作量，比如定期合并Fsimage和Edits，并推送给NameNode ；
    * 在紧急情况下，可辅助恢复NameNode。



## 2.4 HDFS文件块大小

1. HDFS中的文件在物理上是分块存储（Block），块的大小可以通过配置参数( dfs.blocksize)来规定，默认大小在Hadoop2.x版本中是128M，老版本中是64M。
2. 如果寻址时间约为10ms，即查找到目标block的时间为10ms。
3. 寻址时间为传输时间的1%时，则为最佳状态。因此，传输时间=10ms/0.01=1000ms=1s
4. 而目前磁盘的传输速率普遍为100MB/s。

> HDFS的块设置太小，会增加寻址时间，程序一直在找块的开始位置
>
> 如果块设置的太大，从磁盘传输数据的时间会明显大于定位这个块开始位置所需的时间。导致程序在处理这块数据时，会非常慢。
>
> 总结：HDFS块的大小设置主要取决于磁盘传输速率。





## 2.5 HDFS的Shell操作

bin/hadoop fs 具体命令  OR bin/hdfs dfs 具体命令

1. 启动Hadoop集群

    ``` shell
    sbin/start-dfs.sh
    sbin/start-yarn.sh
    ```

2. -help：输出这个命令参数

    ``` shell
    hadoop fs -help rm
    ```

3. -ls: 显示目录信息

    ``` shell
    hadoop fs -ls /
    ```

4. -moveFromLocal：从本地剪切粘贴到HDFS

    ``` shell
    touch qiancijun.txt
    hadoop fs  -moveFromLocal  ./qiancijun.txt  /QianciHome
    ```

5. -appendToFile：追加一个文件到已经存在的文件末尾

    ``` shell
    touch hello.txt
    hadoop fs -appendToFile hello.txt /QianciHome/qiancijun.txt
    ```

6. -cat：显示文件内容

    ``` shell
    hadoop fs -cat /QianciHome/qianicjun.txt
    ```

7. -chgrp 、-chmod、-chown：Linux文件系统中的用法一样，修改文件所属权限

8. -copyFromLocal：从本地文件系统中拷贝文件到HDFS路径去

    ``` shell
    hadoop fs -copyFromLocal README.txt /
    ```

9. -copyToLocal：从HDFS拷贝到本地

    ```  shell
    hadoop fs -copyToLocal /QianciHome/qiancijun.txt ./
    ```

10. -cp ：从HDFS的一个路径拷贝到HDFS的另一个路径

    ``` shell
    hadoop fs -cp /QianciHome/qiancijun.txt /QianciHome2/qiancijun.txt
    ```

11. -mv：在HDFS目录中移动文件

    ``` shell
    hadoop fs -mv /qiancijun.txt /QianciHome2
    ```

12. -get：等同于copyToLocal，就是从HDFS下载文件到本地

13. -getmerge：合并下载多个文件，比如HDFS的目录 /user/atguigu/test下有多个文件:log.1, log.2,log.3,...

14. -put：等同于copyFromLocal

15. -tail：显示一个文件的末尾

16. -rm：删除文件或文件夹

17. -rmdir：删除空目录

18. -du统计文件夹的大小信息

19. -setrep：设置HDFS中文件的副本数量



## 2.6 HDFS客户端操作

### 2.6.1 HDFS客户端环境准备

